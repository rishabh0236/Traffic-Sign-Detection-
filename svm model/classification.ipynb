{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86320eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbimporter in c:\\users\\rishabh\\anaconda3\\lib\\site-packages (0.3.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c7dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af530ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "SIZE = 32\n",
    "CLASS_NUMBER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7436520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = r'D:\\books\\4th year 2nd sem books\\bs project\\dataset\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b01a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_traffic_dataset():\n",
    "#     dataset = []\n",
    "#     labels = []\n",
    "#     for sign_type in range(CLASS_NUMBER):\n",
    "#         sign_list = listdir(\"./dataset/{}\".format(sign_type))\n",
    "#         for sign_file in sign_list:\n",
    "#             if '.png' in sign_file:\n",
    "#                 path = \"./dataset/{}/{}\".format(sign_type,sign_file)\n",
    "#                 print(path)\n",
    "#                 img = cv2.imread(path,0)\n",
    "#                 img = cv2.resize(img, (SIZE, SIZE))\n",
    "#                 img = np.reshape(img, [SIZE, SIZE])\n",
    "#                 dataset.append(img)\n",
    "#                 labels.append(sign_type)\n",
    "#     return np.array(dataset), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871236b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(dataPath):\n",
    "    data = []\n",
    "    for cat in range(CLASS_NUMBER):\n",
    "        label = int(cat[:2])\n",
    "        for i in os.listdir(dataPath+'/'+cat):\n",
    "            imagePath = dataPath+'/'+cat+'/'+i\n",
    "            try:\n",
    "                image = cv2.imread(imagePath,0) \n",
    "                image = cv2.resize(image,(SIZE,SIZE))\n",
    "                dataset.append(image)\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    X = [] #image\n",
    "    Y = [] #labels\n",
    "    for img,l in data: \n",
    "        X.append(img)\n",
    "        Y.append(l)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).reshape(len(Y),1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed535a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11']/m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SIZE*skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (SIZE, SIZE), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    return img\n",
    "\n",
    "class StatModel(object):\n",
    "    def load(self, fn):\n",
    "        self.model.load(fn)  # Known bug: https://github.com/opencv/opencv/issues/4969\n",
    "    def save(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "class SVM(StatModel):\n",
    "    def __init__(self, C = 12.5, gamma = 0.50625):\n",
    "        self.model = cv2.ml.SVM_create()\n",
    "        self.model.setGamma(gamma)\n",
    "        self.model.setC(C)\n",
    "        self.model.setKernel(cv2.ml.SVM_RBF)\n",
    "        self.model.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "    def train(self, samples, responses):\n",
    "        self.model.train(samples, cv2.ml.ROW_SAMPLE, responses)\n",
    "\n",
    "    def predict(self, samples):\n",
    "\n",
    "        return self.model.predict(samples)[1].ravel()\n",
    "\n",
    "\n",
    "def evaluate_model(model, data, samples, labels):\n",
    "    resp = model.predict(samples)\n",
    "    print(resp)\n",
    "    err = (labels != resp).mean()\n",
    "    print('Accuracy: %.2f %%' % ((1 - err)*100))\n",
    "\n",
    "    confusion = np.zeros((10, 10), np.int32)\n",
    "    for i, j in zip(labels, resp):\n",
    "        confusion[int(i), int(j)] += 1\n",
    "    print('confusion matrix:')\n",
    "    print(confusion)\n",
    "\n",
    "\n",
    "def preprocess_simple(data):\n",
    "    return np.float32(data).reshape(-1, SIZE*SIZE) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3825401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog() : \n",
    "    winSize = (20,20)\n",
    "    blockSize = (10,10)\n",
    "    blockStride = (5,5)\n",
    "    cellSize = (10,10)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    signedGradient = True\n",
    "\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradient)\n",
    "\n",
    "    return hog\n",
    "    affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56476116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    def training():\n",
    "        print('Loading data from data.png ... ')\n",
    "        # Load data.\n",
    "        #data, labels = load_data('data.png')\n",
    "        data, labels = load_traffic_dataset()\n",
    "        print(data.shape)\n",
    "        print('Shuffle data ... ')\n",
    "        # Shuffle data\n",
    "        rand = np.random.RandomState(10)\n",
    "        shuffle = rand.permutation(len(data))\n",
    "        data, labels = data[shuffle], labels[shuffle]\n",
    "    \n",
    "        print('Deskew images ... ')\n",
    "        data_deskewed = list(map(deskew, data))\n",
    "    \n",
    "        print('Defining HoG parameters ...')\n",
    "        # HoG feature descriptor\n",
    "        hog = get_hog()\n",
    "\n",
    "        print('Calculating HoG descriptor for every image ... ')\n",
    "        hog_descriptors = []\n",
    "        for img in data_deskewed:\n",
    "            hog_descriptors.append(hog.compute(img))\n",
    "        hog_descriptors = np.squeeze(hog_descriptors)\n",
    "\n",
    "        print('Spliting data into training (90%) and test set (10%)... ')\n",
    "        train_n=int(0.9*len(hog_descriptors))\n",
    "        data_train, data_test = np.split(data_deskewed, [train_n])\n",
    "        hog_descriptors_train, hog_descriptors_test = np.split(hog_descriptors, [train_n])\n",
    "        labels_train, labels_test = np.split(labels, [train_n])\n",
    "    \n",
    "    \n",
    "        print('Training SVM model ...')\n",
    "        model = SVM()\n",
    "        model.train(hog_descriptors_train, labels_train)\n",
    "\n",
    "        print('Saving SVM model ...')\n",
    "        model.save('data_svm.dat')\n",
    "        return model\n",
    "\n",
    "    def getLabel(model, data):\n",
    "        gray = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "        img = [cv2.resize(gray,(SIZE,SIZE))]\n",
    "        #print(np.array(img).shape)\n",
    "        img_deskewed = list(map(deskew, img))\n",
    "        hog = get_hog()\n",
    "        hog_descriptors = np.array([hog.compute(img_deskewed[0])])\n",
    "        hog_descriptors = np.reshape(hog_descriptors, [-1, hog_descriptors.shape[1]])\n",
    "        return int(model.predict(hog_descriptors)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd33dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "import imutils\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "SIGNS = [\"Sign Board\",\"General Board\"]\n",
    "\n",
    "# Clean all previous file\n",
    "def clean_images():\n",
    "\tfile_list = os.listdir('./')\n",
    "\tfor file_name in file_list:\n",
    "\t\tif '.png' in file_name:\n",
    "\t\t\tos.remove(file_name)\n",
    "\n",
    "\n",
    "### Preprocess image\n",
    "def constrastLimit(image):\n",
    "    img_hist_equalized = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    channels = cv2.split(img_hist_equalized)\n",
    "    channels[0] = cv2.equalizeHist(channels[0])\n",
    "    img_hist_equalized = cv2.merge(channels)\n",
    "    img_hist_equalized = cv2.cvtColor(img_hist_equalized, cv2.COLOR_YCrCb2BGR)\n",
    "    return img_hist_equalized\n",
    "\n",
    "def LaplacianOfGaussian(image):\n",
    "    LoG_image = cv2.GaussianBlur(image, (3,3), 0)           # paramter \n",
    "    gray = cv2.cvtColor( LoG_image, cv2.COLOR_BGR2GRAY)\n",
    "    LoG_image = cv2.Laplacian( gray, cv2.CV_8U,3,3,2)       # parameter\n",
    "    LoG_image = cv2.convertScaleAbs(LoG_image)\n",
    "    return LoG_image\n",
    "    \n",
    "def binarization(image):\n",
    "    thresh = cv2.threshold(image,32,255,cv2.THRESH_BINARY)[1]\n",
    "    #thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    return thresh\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = constrastLimit(image)\n",
    "    image = LaplacianOfGaussian(image)\n",
    "    image = binarization(image)\n",
    "    return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9b45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Signs\n",
    "def removeSmallComponents(image, threshold):\n",
    "    #find all your connected components (white blobs in your image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "    img2 = np.zeros((output.shape),dtype = np.uint8)\n",
    "    #for every component in the image, you keep it only if it's above threshold\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= threshold:\n",
    "            img2[output == i + 1] = 255\n",
    "    return img2\n",
    "\n",
    "def findContour(image):\n",
    "    #find contours in the thresholded image\n",
    "    cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE    )\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "    return cnts\n",
    "\n",
    "def contourIsSign(perimeter, centroid, threshold):\n",
    "    #  perimeter, centroid, threshold\n",
    "    # # Compute signature of contour\n",
    "    result=[]\n",
    "    for p in perimeter:\n",
    "        p = p[0]\n",
    "        distance = sqrt((p[0] - centroid[0])**2 + (p[1] - centroid[1])**2)\n",
    "        result.append(distance)\n",
    "    max_value = max(result)\n",
    "    signature = [float(dist) / max_value for dist in result ]\n",
    "    # Check signature of contour.\n",
    "    temp = sum((1 - s) for s in signature)\n",
    "    temp = temp / len(signature)\n",
    "    if temp < threshold: # is  the sign\n",
    "        return True, max_value + 2\n",
    "    else:                 # is not the sign\n",
    "        return False, max_value + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c68c3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop sign \n",
    "def cropContour(image, center, max_distance):\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    top = max([int(center[0] - max_distance), 0])\n",
    "    bottom = min([int(center[0] + max_distance + 1), height-1])\n",
    "    left = max([int(center[1] - max_distance), 0])\n",
    "    right = min([int(center[1] + max_distance+1), width-1])\n",
    "    print(left, right, top, bottom)\n",
    "    return image[left:right, top:bottom]\n",
    "\n",
    "def cropSign(image, coordinate):\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    top = max([int(coordinate[0][1]), 0])\n",
    "    bottom = min([int(coordinate[1][1]), height-1])\n",
    "    left = max([int(coordinate[0][0]), 0])\n",
    "    right = min([int(coordinate[1][0]), width-1])\n",
    "    #print(top,left,bottom,right)\n",
    "    return image[top:bottom,left:right]\n",
    "\n",
    "\n",
    "def findLargestSign(image, contours, threshold, distance_theshold):\n",
    "    max_distance = 0\n",
    "    coordinate = None\n",
    "    sign = None\n",
    "    for c in contours:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        is_sign, distance = contourIsSign(c, [cX, cY], 1-threshold)\n",
    "        if is_sign and distance > max_distance and distance > distance_theshold:\n",
    "            max_distance = distance\n",
    "            coordinate = np.reshape(c, [-1,2])\n",
    "            left, top = np.amin(coordinate, axis=0)\n",
    "            right, bottom = np.amax(coordinate, axis = 0)\n",
    "            coordinate = [(left-2,top-2),(right+3,bottom+1)]\n",
    "            sign = cropSign(image,coordinate)\n",
    "    return sign, coordinate\n",
    "\n",
    "\n",
    "def findSigns(image, contours, threshold, distance_theshold):\n",
    "    signs = []\n",
    "    coordinates = []\n",
    "    for c in contours:\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        is_sign, max_distance = contourIsSign(c, [cX, cY], 1-threshold)\n",
    "        if is_sign and max_distance > distance_theshold:\n",
    "            sign = cropContour(image, [cX, cY], max_distance)\n",
    "            signs.append(sign)\n",
    "            coordinate = np.reshape(c, [-1,2])\n",
    "            top, left = np.amin(coordinate, axis=0)\n",
    "            right, bottom = np.amax(coordinate, axis = 0)\n",
    "            coordinates.append([(top-2,left-2),(right+1,bottom+1)])\n",
    "    return signs, coordinates\n",
    "\n",
    "def localization(image, min_size_components, similitary_contour_with_circle, model, count, current_sign_type):\n",
    "    original_image = image.copy()\n",
    "    binary_image = preprocess_image(image)\n",
    "\n",
    "    binary_image = removeSmallComponents(binary_image, min_size_components)\n",
    "\n",
    "    binary_image = cv2.bitwise_and(binary_image,binary_image, mask=remove_other_color(image))\n",
    "\n",
    "    #binary_image = remove_line(binary_image)\n",
    "\n",
    "    cv2.imshow('BINARY IMAGE', binary_image)\n",
    "    contours = findContour(binary_image)\n",
    "    #signs, coordinates = findSigns(image, contours, similitary_contour_with_circle, 15)\n",
    "    sign, coordinate = findLargestSign(original_image, contours, similitary_contour_with_circle, 15)\n",
    "    \n",
    "    text = \"\"\n",
    "    sign_type = -1\n",
    "    i = 0\n",
    "\n",
    "    if sign is not None:\n",
    "        sign_type = getLabel(model, sign)\n",
    "        sign_type = sign_type if sign_type <= 8 else 8\n",
    "        text = SIGNS[sign_type]\n",
    "        cv2.imwrite(str(count)+'_'+text+'.png', sign)\n",
    "\n",
    "    if sign_type > 0 and sign_type != current_sign_type:        \n",
    "        cv2.rectangle(original_image, coordinate[0],coordinate[1], (0, 255, 0), 1)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        cv2.putText(original_image,text,(coordinate[0][0], coordinate[0][1] -15), font, 1,(0,0,255),2,cv2.LINE_4)\n",
    "    return coordinate, original_image, sign_type, text\n",
    "\n",
    "def remove_line(img):\n",
    "    gray = img.copy()\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    minLineLength = 5\n",
    "    maxLineGap = 3\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,15,minLineLength,maxLineGap)\n",
    "    mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(mask,(x1,y1),(x2,y2),(0,0,0),2)\n",
    "    return cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "def remove_other_color(img):\n",
    "    frame = cv2.GaussianBlur(img, (3,3), 0) \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([100,128,0])\n",
    "    upper_blue = np.array([215,255,255])\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    lower_white = np.array([0,0,128], dtype=np.uint8)\n",
    "    upper_white = np.array([255,255,255], dtype=np.uint8)\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    lower_black = np.array([0,0,0], dtype=np.uint8)\n",
    "    upper_black = np.array([170,150,50], dtype=np.uint8)\n",
    "\n",
    "    mask_black = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "    mask_1 = cv2.bitwise_or(mask_blue, mask_white)\n",
    "    mask = cv2.bitwise_or(mask_1, mask_black)\n",
    "    # Bitwise-AND mask and original image\n",
    "    #res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baea55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--file_name FILE_NAME] [--min_size_components MIN_SIZE_COMPONENTS]\n",
      "                             [--similitary_contour_with_circle SIMILITARY_CONTOUR_WITH_CIRCLE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\RISHABH\\AppData\\Roaming\\jupyter\\runtime\\kernel-41a09878-ab03-4e49-844c-567a8cf6ae06.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RISHABH\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(args):\n",
    "\t#Clean previous image    \n",
    "    clean_images()\n",
    "    #Training phase\n",
    "    model = training()\n",
    "\n",
    "    vidcap = cv2.VideoCapture(args.file_name)\n",
    "\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    width = vidcap.get(3)  # float\n",
    "    height = vidcap.get(4) # float\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output.avi',fourcc, fps , (640,480))\n",
    "\n",
    "    # initialize the termination criteria for cam shift, indicating\n",
    "    # a maximum of ten iterations or movement by a least one pixel\n",
    "    # along with the bounding box of the ROI\n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "    roiBox = None\n",
    "    roiHist = None\n",
    "\n",
    "    success = True\n",
    "    similitary_contour_with_circle = 0.65   # parameter\n",
    "    count = 0\n",
    "    current_sign = None\n",
    "    current_text = \"\"\n",
    "    current_size = 0\n",
    "    sign_count = 0\n",
    "    coordinates = []\n",
    "    position = []\n",
    "    file = open(\"Output.txt\", \"w\")\n",
    "    while True:\n",
    "        success,frame = vidcap.read()\n",
    "        if not success:\n",
    "            print(\"FINISHED\")\n",
    "            break\n",
    "        width = frame.shape[1]\n",
    "        height = frame.shape[0]\n",
    "        #frame = cv2.resize(frame, (640,int(height/(width/640))))\n",
    "        frame = cv2.resize(frame, (640,480))\n",
    "\n",
    "        print(\"Frame:{}\".format(count))\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        coordinate, image, sign_type, text = localization(frame, args.min_size_components, args.similitary_contour_with_circle, model, count, current_sign)\n",
    "        if coordinate is not None:\n",
    "            cv2.rectangle(image, coordinate[0],coordinate[1], (255, 255, 255), 1)\n",
    "        print(\"Sign:{}\".format(sign_type))\n",
    "        if sign_type > 0 and (not current_sign or sign_type != current_sign):\n",
    "            current_sign = sign_type\n",
    "            current_text = text\n",
    "            top = int(coordinate[0][1]*1.05)\n",
    "            left = int(coordinate[0][0]*1.05)\n",
    "            bottom = int(coordinate[1][1]*0.95)\n",
    "            right = int(coordinate[1][0]*0.95)\n",
    "\n",
    "            position = [count, sign_type if sign_type <= 8 else 8, coordinate[0][0], coordinate[0][1], coordinate[1][0], coordinate[1][1]]\n",
    "            cv2.rectangle(image, coordinate[0],coordinate[1], (0, 255, 0), 1)\n",
    "            font = cv2.FONT_HERSHEY_PLAIN\n",
    "            cv2.putText(image,text,(coordinate[0][0], coordinate[0][1] -15), font, 1,(0,0,255),2,cv2.LINE_4)\n",
    "\n",
    "            tl = [left, top]\n",
    "            br = [right,bottom]\n",
    "            print(tl, br)\n",
    "            current_size = math.sqrt(math.pow((tl[0]-br[0]),2) + math.pow((tl[1]-br[1]),2))\n",
    "            # grab the ROI for the bounding box and convert it\n",
    "            # to the HSV color space\n",
    "            roi = frame[tl[1]:br[1], tl[0]:br[0]]\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            #roi = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "            # compute a HSV histogram for the ROI and store the\n",
    "            # bounding box\n",
    "            roiHist = cv2.calcHist([roi], [0], None, [16], [0, 180])\n",
    "            roiHist = cv2.normalize(roiHist, roiHist, 0, 255, cv2.NORM_MINMAX)\n",
    "            roiBox = (tl[0], tl[1], br[0], br[1])\n",
    "\n",
    "        elif current_sign:\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            backProj = cv2.calcBackProject([hsv], [0], roiHist, [0, 180], 1)\n",
    "\n",
    "            # apply cam shift to the back projection, convert the\n",
    "            # points to a bounding box, and then draw them\n",
    "            (r, roiBox) = cv2.CamShift(backProj, roiBox, termination)\n",
    "            pts = np.int0(cv2.boxPoints(r))\n",
    "            s = pts.sum(axis = 1)\n",
    "            tl = pts[np.argmin(s)]\n",
    "            br = pts[np.argmax(s)]\n",
    "            size = math.sqrt(pow((tl[0]-br[0]),2) +pow((tl[1]-br[1]),2))\n",
    "            print(size)\n",
    "\n",
    "            if  current_size < 1 or size < 1 or size / current_size > 30 or math.fabs((tl[0]-br[0])/(tl[1]-br[1])) > 2 or math.fabs((tl[0]-br[0])/(tl[1]-br[1])) < 0.5:\n",
    "                current_sign = None\n",
    "                print(\"Stop tracking\")\n",
    "            else:\n",
    "                current_size = size\n",
    "\n",
    "            if sign_type > 0:\n",
    "                top = int(coordinate[0][1])\n",
    "                left = int(coordinate[0][0])\n",
    "                bottom = int(coordinate[1][1])\n",
    "                right = int(coordinate[1][0])\n",
    "\n",
    "                position = [count, sign_type if sign_type <= 8 else 8, left, top, right, bottom]\n",
    "                cv2.rectangle(image, coordinate[0],coordinate[1], (0, 255, 0), 1)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                cv2.putText(image,text,(coordinate[0][0], coordinate[0][1] -15), font, 1,(0,0,255),2,cv2.LINE_4)\n",
    "            elif current_sign:\n",
    "                position = [count, sign_type if sign_type <= 8 else 8, tl[0], tl[1], br[0], br[1]]\n",
    "                cv2.rectangle(image, (tl[0], tl[1]),(br[0], br[1]), (0, 255, 0), 1)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                cv2.putText(image,current_text,(tl[0], tl[1] -15), font, 1,(0,0,255),2,cv2.LINE_4)\n",
    "\n",
    "        if current_sign:\n",
    "            sign_count += 1\n",
    "            coordinates.append(position)\n",
    "\n",
    "        cv2.imshow('Result', image)\n",
    "        count = count + 1\n",
    "        #Write to video\n",
    "        out.write(image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    file.write(\"{}\".format(sign_count))\n",
    "    for pos in coordinates:\n",
    "        file.write(\"\\n{} {} {} {} {} {}\".format(pos[0],pos[1],pos[2],pos[3],pos[4], pos[5]))\n",
    "    print(\"Finish {} frames\".format(count))\n",
    "    file.close()\n",
    "    return \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"NLP Assignment Command Line\")\n",
    "    \n",
    "    parser.add_argument(\n",
    "      '--file_name',\n",
    "      default= \"./MVI_1049.avi\",\n",
    "      help= \"Video to be analyzed\"\n",
    "      )\n",
    "    \n",
    "    parser.add_argument(\n",
    "      '--min_size_components',\n",
    "      type = int,\n",
    "      default= 300,\n",
    "      help= \"Min size component to be reserved\"\n",
    "      )\n",
    "\n",
    "    \n",
    "    parser.add_argument(\n",
    "      '--similitary_contour_with_circle',\n",
    "      type = float,\n",
    "      default= 0.65,\n",
    "      help= \"Similitary to a circle\"\n",
    "      )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fc424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c002a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
